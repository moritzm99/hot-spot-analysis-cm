{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f998432d-ed63-4aa5-8a60-2fc0ee479f27",
   "metadata": {},
   "source": [
    "# Notebook for Hot and Cold spot analysis with Copernicus Marine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2c599-2ecf-49a0-a99c-b1a5307630fc",
   "metadata": {},
   "source": [
    "**USER INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ec5190-1a35-42f5-b212-5c623e7fd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input dictionary for copernicus marine toolbox API, if other query desired just CHANGE dictionary input values\n",
    "\n",
    "# dataset_id defines the product to be queried, by default set to sea surface temperature \n",
    "# variables defines a list of variables selected from the product (identifer = dataset_id), by default set to adjusted sea surface temperature\n",
    "# max and min lat/lat define the bounding box of the query, by default set to the whole Agean sea \n",
    "# start/end_datetime define the time period covered by the dataset, by default set to winter 2023/24\n",
    "input_dict = {\n",
    "    \"dataset_id\": \"SST_MED_SST_L3S_NRT_OBSERVATIONS_010_012_b\", \n",
    "    \"variables\": [\"adjusted_sea_surface_temperature\"], \n",
    "    \"minimum_longitude\": 19.22659983450641, \n",
    "    \"maximum_longitude\": 28.439441984120553, \n",
    "    \"minimum_latitude\": 34.62160284496615, \n",
    "    \"maximum_latitude\": 40.9634662781889, \n",
    "    \"start_datetime\": \"2023-12-01T00:00:00\", \n",
    "    \"end_datetime\": \"2024-02-28T00:00:00\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef62d3c3-04e2-4393-b7a3-92938910a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define units of your chosen data variable, since default variable is sea surface temperature => unit is set to degree Celsius \n",
    "unit = \"°C\"\n",
    "# define abreviation of your data variable (coming from the server they usually have quite clumsy names), since defualt variable is sea surface temperature => abreviation is set to 'sst'\n",
    "variable_abreviation = \"sst\"\n",
    "\n",
    "DOI = \"https://doi.org/10.48670/moi-00171\"\n",
    "\n",
    "spatial_resolution = \"0.01° × 0.01°\"\n",
    "\n",
    "temporal_resolution = \"Daily\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3529e8-b621-405e-82ad-3e8600f2323e",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5666148c-471b-4d32-9052-7a7a5a44acb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# necessary libraries to run this NOTEBOOK\n",
    "# if not already installed, install via conda-forge channel using Ana(Mini)conda, Micromamba or pip or use requirements.yml in \n",
    "import copernicusmarine\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from esda.getisord import G_Local\n",
    "from libpysal.weights import Queen\n",
    "from pyproj import CRS\n",
    "import contextily as ctx\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "import pathlib\n",
    "import os\n",
    "from rasterio.warp import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd015156-3477-49cb-aa74-ca70a4d30fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving realtive paths\n",
    "NOTEBOOK_DIRECTORY = pathlib.Path().resolve()\n",
    "OUTPUT_DIRECTORY = NOTEBOOK_DIRECTORY / \"output\" / \"getis_plots\"\n",
    "BASIC_PLOTS = NOTEBOOK_DIRECTORY / \"output\" / \"basic_plots\"\n",
    "DATA_DIRECTORY = NOTEBOOK_DIRECTORY / \"output\" / \"data\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(BASIC_PLOTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763bcc31-af9b-4dc3-95c3-9ee24c7e5817",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084b0d95-e3d2-4324-9ab6-e5a88ebcf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for fetching a copernicus marine dataset via 'lazy-loading' to NOTEBOOK\n",
    "def get_cm_dataset(input_dict):\n",
    "    dataset = copernicusmarine.open_dataset(\n",
    "        dataset_id=input_dict[\"dataset_id\"],\n",
    "        variables=input_dict[\"variables\"],\n",
    "        minimum_longitude=input_dict[\"minimum_longitude\"],\n",
    "        maximum_longitude=input_dict[\"maximum_longitude\"],\n",
    "        minimum_latitude=input_dict[\"minimum_latitude\"],\n",
    "        maximum_latitude=input_dict[\"maximum_latitude\"],\n",
    "        start_datetime=input_dict[\"start_datetime\"],\n",
    "        end_datetime=input_dict[\"end_datetime\"],\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataset fetched via API and loaded into RAM\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabfefc3-20a6-46bf-9282-a2d73c5306eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for pre-processing fetched dataset\n",
    "def pre_processing(dataset, variable_abreviation):\n",
    "    # renaming data variable\n",
    "    dataset = dataset.rename({\"adjusted_sea_surface_temperature\": variable_abreviation})\n",
    "    # converting Kelvin to Celsius\n",
    "    dataset[variable_abreviation] = dataset[variable_abreviation]-273.15\n",
    "\n",
    "    dataset = dataset.rio.write_crs(CRS.from_epsg(4326))\n",
    "\n",
    "    dataset = dataset.rio.reproject(CRS.from_epsg(3857))\n",
    "\n",
    "    print(\"\\nDataset pre-processing finished\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad17697e-f5bf-4559-a703-36331d9c6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating basic stats on sst\n",
    "def bstats(dataset_preprocessed, variable_abreviation):\n",
    "    # computing mean\n",
    "    dataset_mean = dataset_preprocessed[variable_abreviation].mean(dim=\"time\", skipna=True)\n",
    "    # computing median\n",
    "    dataset_mean = dataset_preprocessed[variable_abreviation].median(dim=\"time\", skipna=True)\n",
    "    # computing standard deviation\n",
    "    dataset_std = dataset_preprocessed[variable_abreviation].std(dim=\"time\", skipna=True)\n",
    "\n",
    "    print(\"Basic statistics calculation finished\")\n",
    "\n",
    "    return dataset_mean, dataset_mean, dataset_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b055f84d-dfcd-4ad0-a948-e5d31f4f6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing GETIS ORD G* statistics\n",
    "def getis_ord_g(dataset_median, variable_abreviation):\n",
    "    # converting data array to pandas DataFrame \n",
    "    df = dataset_median.to_dataframe().reset_index()\n",
    "    # droping NANs \n",
    "    df.dropna(subset=[variable_abreviation], inplace=True)\n",
    "    # converting dataframe to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"x\"], df[\"y\"]))\n",
    "    # computing Spatial Weights (Queen contiguity)\n",
    "    w = Queen.from_dataframe(gdf, use_index=False)\n",
    "    # applying Getis-Ord Gi*\n",
    "    getisord = G_Local(gdf[variable_abreviation], w, star=True, transform=\"B\")\n",
    "    # computing Z-scores for hot/cold spots\n",
    "    gdf[\"G\"] = getisord.Zs  \n",
    "\n",
    "    print(\"Calculation of GETIS-ORD G* statistic finished\")\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ba720a-a036-4435-879f-8ac3a1229a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the 95th percentile of the dataset, filtering by values per pixel > 95th percentile, calculating the median over time\n",
    "def percentile_5th(dataset, variable_abreviation):\n",
    "    # computing the 95th percentile per pixel\n",
    "    percentile_95th = dataset[variable_abreviation].quantile(0.95, dim=\"time\")\n",
    "    # masking values below 95th percentile\n",
    "    top5 = dataset[variable_abreviation].where(dataset[variable_abreviation] >= percentile_95th)\n",
    "    # calculating the median over time of values above  95th percentile\n",
    "    top5_median = top5.median(dim=\"time\", skipna=True)\n",
    "\n",
    "    print(\"\\nCalculation of 5% highest values finished\")\n",
    "\n",
    "    return top5_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c489e0ec-f16e-4343-b285-3957b55af3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(dataset_mean, dataset_median, dataset_std, top5, input_dict, \n",
    "                  variable_abreviation, unit, DOI, temporal_resolution, spatial_resolution):\n",
    "    \"\"\"\n",
    "    Generates and saves three visualizations (mean, median, std) with correct projection handling.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_mean (xarray.DataArray): Mean values of the dataset.\n",
    "        dataset_median (xarray.DataArray): Median values of the dataset.\n",
    "        dataset_std (xarray.DataArray): Standard deviation values of the dataset.\n",
    "        top5 (xarray.DataArray): 5% highest values.\n",
    "        input_dict (dict): Dictionary containing metadata including start and end datetime.\n",
    "        variable_abreviation (str): Variable abbreviation (e.g., SST for sea surface temperature).\n",
    "        unit (str): Unit of measurement.\n",
    "        DOI (str): Dataset DOI for attribution.\n",
    "        temporal_resolution (str): Temporal resolution of dataset.\n",
    "        spatial_resolution (str): Spatial resolution of dataset.\n",
    "    \"\"\"\n",
    "    attribution = (f\"Author: Moritz Mühlbauer 2025 in cooperation with Archipelagos\\n\"\n",
    "                   f\"Source: Generated using E.U. Copernicus Marine Service Information,\\n\"\n",
    "                   f\"DOI: {DOI}\\n\"\n",
    "                   f\"Dataset ID: {input_dict['dataset_id']}\\n\"\n",
    "                   f\"Spatial resolution: {spatial_resolution}\\n\"\n",
    "                   f\"Temporal resolution: {temporal_resolution}\\n\"\n",
    "                   f\"Projection: WEB MERCATOR (EPSG:3857)\\n\"\n",
    "                   f\"Basemap: Esri World Imagery\"\n",
    "                  )\n",
    "\n",
    "    # Generate a timestamp for unique filenames\n",
    "    start_date = input_dict[\"start_datetime\"][:10]\n",
    "    end_date = input_dict[\"end_datetime\"][:10]\n",
    "\n",
    "    # Get min and max values\n",
    "    min_value = dataset_median.min().item()\n",
    "    max_value = top5.max().item()\n",
    "\n",
    "    # Define filenames (keys now match dataset names)\n",
    "    filenames = {\n",
    "        \"Mean\": f\"mean_{variable_abreviation}_{start_date}-{end_date}.png\",\n",
    "        \"Median\": f\"median_{variable_abreviation}_{start_date}-{end_date}.png\",\n",
    "        \"Standard Deviation\": f\"std_{variable_abreviation}_{start_date}-{end_date}.png\",\n",
    "        \"5% Highest Values\": f\"top5_{variable_abreviation}_{start_date}-{end_date}.png\",\n",
    "    }\n",
    "\n",
    "    # Define dataset dictionary (keys match filenames)\n",
    "    datasets = {\n",
    "        \"Mean\": dataset_mean,\n",
    "        \"Median\": dataset_median,\n",
    "        \"Standard Deviation\": dataset_std,\n",
    "        \"5% Highest Values\": top5,\n",
    "    }\n",
    "    \n",
    "    # Define colormap dictionary\n",
    "    colormaps = {\n",
    "        \"Mean\": \"RdBu_r\",\n",
    "        \"Median\": \"RdBu_r\",\n",
    "        \"Standard Deviation\": \"magma\",\n",
    "        \"5% Highest Values\": \"RdBu_r\",\n",
    "    }\n",
    "    \n",
    "    # Define min/max limits for consistent color scaling\n",
    "    vmin_vmax = {\n",
    "        \"Mean\": (None, None),\n",
    "        \"Median\": (min_value, max_value),\n",
    "        \"Standard Deviation\": (None, None),\n",
    "        \"5% Highest Values\": (min_value, max_value),\n",
    "    }\n",
    "\n",
    "    # Plot each dataset\n",
    "    for key, data in datasets.items():\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Use xarray's plot function with a proper colorbar label\n",
    "        data.plot(ax=ax, cmap=colormaps[key], vmin=vmin_vmax[key][0], vmax=vmin_vmax[key][1],\n",
    "                  cbar_kwargs={'label': unit})  # <-- This sets the colorbar label\n",
    "\n",
    "        ctx.add_basemap(ax, source=ctx.providers.Esri.WorldImagery, attribution=\"\") \n",
    "\n",
    "        ax.set_title(f\"{key} {variable_abreviation} ({start_date} - {end_date})\\n\")\n",
    "        ax.set_xlabel(\"Easting (meters)\")\n",
    "        ax.set_ylabel(\"Northing (meters)\")\n",
    "\n",
    "        # Add attribution text\n",
    "        ax.text(0.01, -0.18, attribution, fontsize=6, transform=ax.transAxes, \n",
    "                fontweight='normal', bbox={'facecolor': 'none', 'pad': 0.01, 'edgecolor': 'none'})\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(os.path.join(BASIC_PLOTS, filenames[key]), dpi=600, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"Plots saved in {BASIC_PLOTS}:\")\n",
    "    for file in filenames.values():\n",
    "        print(f\" - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d9b376-9e88-401c-97ea-f35f6b32537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting getis statistic over the entire dataset\n",
    "def getis_viz(gdf, input_dict, variable_abreviation):\n",
    "    gdf = gdf.set_crs(CRS.from_epsg(3857))\n",
    "    \n",
    "    # Define metadata for attribution\n",
    "    attribution = (f\"Author: Moritz Mühlbauer 2025 in cooperation with Archipelagos\\n\"\n",
    "                   f\"Source: Generated using E.U. Copernicus Marine Service Information,\\n\"\n",
    "                   f\"DOI: {DOI}\\n\"\n",
    "                   f\"Dataset ID: {input_dict['dataset_id']}\\n\"\n",
    "                   f\"Spatial resolution: {spatial_resolution}\\n\"\n",
    "                   f\"Temporal resolution: {temporal_resolution}\\n\"\n",
    "                   f\"Projection: WEB MERCATOR (EPSG:3857)\\n\"\n",
    "                   f\"Basemap: Esri World Imagery\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Add attribution text\n",
    "    ax.text(1.02, 0.01, attribution, fontsize=5.5, transform=ax.transAxes, \n",
    "            fontweight='normal', bbox={'facecolor': 'none', 'pad': 0.01, 'edgecolor': 'none'})\n",
    "    \n",
    "    # Ensure bins are strictly within 7 categories\n",
    "    min_G = gdf[\"G\"].min()\n",
    "    max_G = gdf[\"G\"].max()\n",
    "    bins = [-float(\"inf\"), -2.58, -1.96, -1.65, 1.65, 1.96, 2.58, float(\"inf\")]  # Strict binning\n",
    "\n",
    "    gdf[\"Hotspot_Category\"] = pd.cut(\n",
    "    gdf[\"G\"],\n",
    "    bins=bins,\n",
    "    labels=[\n",
    "        \"Very Cold (< -2.58)\",\n",
    "        \"Cold Spot (-2.58 to -1.96)\",\n",
    "        \"Moderate Cold (-1.95 to -1.65)\",\n",
    "        \"Not Significant (-1.64 to 1.65)\",\n",
    "        \"Moderate Hot (1.66 to 1.96)\",\n",
    "        \"Hot Spot (1.97 to 2.58)\",\n",
    "        \"Very Hot (> 2.58)\"\n",
    "    ],\n",
    "    include_lowest=True\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Generate the plot\n",
    "    gdf.plot(\n",
    "        ax=ax,\n",
    "        column=\"Hotspot_Category\",\n",
    "        cmap=\"coolwarm\",\n",
    "        legend=True,\n",
    "        categorical=True,  # Ensure it's treated as a category\n",
    "        edgecolor=\"none\",\n",
    "        markersize=0.3\n",
    "    )\n",
    "    \n",
    "    # Fix the legend manually\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        legend_texts = leg.get_texts()[:7]  # Ensure only 7 labels are used\n",
    "        for text, new_label in zip(legend_texts, gdf[\"Hotspot_Category\"].cat.categories):\n",
    "            text.set_text(new_label)\n",
    "\n",
    "\n",
    "    \n",
    "    ax.get_legend().set_bbox_to_anchor((1, 1))\n",
    "    ax.get_legend().set_title(f\"Getis-Ord Gi* Z-scores\\n\")\n",
    "    \n",
    "    # Add basemap\n",
    "    ctx.add_basemap(ax, source=ctx.providers.Esri.WorldImagery, attribution=\"\", zoom=8) \n",
    "    \n",
    "    # Extract dates from input dictionary\n",
    "    start_date = input_dict[\"start_datetime\"][:10]\n",
    "    end_date = input_dict[\"end_datetime\"][:10]\n",
    "    \n",
    "    # Define title and filename\n",
    "    title = f\"Hot and Cold Spot Analysis of Median {variable_abreviation} / entire dataset ({start_date} - {end_date})\\n\"\n",
    "    filename = f\"getis_entire_dataset_{variable_abreviation}_{start_date}-{end_date}.png\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    \n",
    "    # Save figure\n",
    "    output_fp = os.path.join(OUTPUT_DIRECTORY, filename)\n",
    "    plt.savefig(output_fp, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Plot of GETIS ORD G* Statistics saved to: {output_fp}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91fcb43-8d82-4a42-a664-7d00f76c6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting getis statistics over the 5 % highest values\n",
    "def getis_top5_viz(gdf, input_dict, variable_abreviation):\n",
    "    gdf = gdf.set_crs(CRS.from_epsg(3857))\n",
    "    \n",
    "    # Define metadata for attribution\n",
    "    attribution = (f\"Author: Moritz Mühlbauer 2025 in cooperation with Archipelagos\\n\"\n",
    "                   f\"Source: Generated using E.U. Copernicus Marine Service Information,\\n\"\n",
    "                   f\"DOI: {DOI}\\n\"\n",
    "                   f\"Dataset ID: {input_dict['dataset_id']}\\n\"\n",
    "                   f\"Spatial resolution: {spatial_resolution}\\n\"\n",
    "                   f\"Temporal resolution: {temporal_resolution}\\n\"\n",
    "                   f\"Projection: WEB MERCATOR (EPSG:3857)\\n\"\n",
    "                   f\"Basemap: Esri World Imagery\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Add attribution text\n",
    "    ax.text(1.02, 0.01, attribution, fontsize=5.5, transform=ax.transAxes, \n",
    "            fontweight='normal', bbox={'facecolor': 'none', 'pad': 0.01, 'edgecolor': 'none'})\n",
    "    \n",
    "    # Ensure bins are strictly within 7 categories\n",
    "    min_G = gdf[\"G\"].min()\n",
    "    max_G = gdf[\"G\"].max()\n",
    "    bins = [-float(\"inf\"), -2.58, -1.96, -1.65, 1.65, 1.96, 2.58, float(\"inf\")]  # Strict binning\n",
    "\n",
    "    gdf[\"Hotspot_Category\"] = pd.cut(\n",
    "    gdf[\"G\"],\n",
    "    bins=bins,\n",
    "    labels=[\n",
    "        \"Very Cold (< -2.58)\",\n",
    "        \"Cold Spot (-2.58 to -1.96)\",\n",
    "        \"Moderate Cold (-1.95 to -1.65)\",\n",
    "        \"Not Significant (-1.64 to 1.65)\",\n",
    "        \"Moderate Hot (1.66 to 1.96)\",\n",
    "        \"Hot Spot (1.97 to 2.58)\",\n",
    "        \"Very Hot (> 2.58)\"\n",
    "    ],\n",
    "    include_lowest=True\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Generate the plot\n",
    "    gdf.plot(\n",
    "        ax=ax,\n",
    "        column=\"Hotspot_Category\",\n",
    "        cmap=\"coolwarm\",\n",
    "        legend=True,\n",
    "        categorical=True,  # Ensure it's treated as a category\n",
    "        edgecolor=\"none\",\n",
    "        markersize=0.3\n",
    "    )\n",
    "    \n",
    "    # Fix the legend manually\n",
    "    leg = ax.get_legend()\n",
    "    if leg:\n",
    "        legend_texts = leg.get_texts()[:7]  # Ensure only 7 labels are used\n",
    "        for text, new_label in zip(legend_texts, gdf[\"Hotspot_Category\"].cat.categories):\n",
    "            text.set_text(new_label)\n",
    "\n",
    "\n",
    "    \n",
    "    ax.get_legend().set_bbox_to_anchor((1, 1))\n",
    "    ax.get_legend().set_title(f\"Getis-Ord Gi* Z-scores\\n\")\n",
    "    \n",
    "    # Add basemap\n",
    "    ctx.add_basemap(ax, source=ctx.providers.Esri.WorldImagery, attribution=\"\", zoom=8) \n",
    "    \n",
    "    # Extract dates from input dictionary\n",
    "    start_date = input_dict[\"start_datetime\"][:10]\n",
    "    end_date = input_dict[\"end_datetime\"][:10]\n",
    "    \n",
    "    # Define title and filename\n",
    "    title = f\"Hot and Cold Spot Analysis of Median {variable_abreviation} / 5% highest values ({start_date} - {end_date})\\n\"\n",
    "    filename = f\"getis_top5_{variable_abreviation}_{start_date}-{end_date}.png\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    \n",
    "    # Save figure\n",
    "    output_fp = os.path.join(OUTPUT_DIRECTORY, filename)\n",
    "    plt.savefig(output_fp, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Plot of GETIS ORD G* Statistics saved to: {output_fp}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2dd828-db32-4463-8faf-01767eef2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export getis statistics GeoDataFrames\n",
    "def export_getis(getis_statistics, getis_top5, input_dict, variable_abreviation):\n",
    "\n",
    "    # Generate a timestamp for unique filenames\n",
    "    start_date = input_dict[\"start_datetime\"][:10]\n",
    "    end_date = input_dict[\"end_datetime\"][:10]\n",
    "\n",
    "    # assign CRS\n",
    "    getis_statistics = getis_statistics.set_crs(CRS.from_epsg(3857))\n",
    "    getis_top5 = getis_top5.set_crs(CRS.from_epsg(3857))\n",
    "\n",
    "    # define filenames \n",
    "    filename_top5 = f\"getis_top5_{variable_abreviation}_{start_date}-{end_date}.gpkg\"\n",
    "    filename_ed = f\"getis_entire_dataset_{variable_abreviation}_{start_date}-{end_date}.gpkg\"\n",
    "\n",
    "    # create filepaths\n",
    "    output_fp_top5 = os.path.join(DATA_DIRECTORY, filename_top5)\n",
    "    output_fp_ed = os.path.join(DATA_DIRECTORY, filename_ed)\n",
    "    \n",
    "    # write to Geopackage\n",
    "    getis_top5.to_file(output_fp_top5, driver=\"GPKG\")\n",
    "    getis_statistics.to_file(output_fp_ed, driver=\"GPKG\")\n",
    "\n",
    "    print(f\"Datsets saved in {DATA_DIRECTORY}:\")\n",
    "    print(f\"  - {filename_top5}\")\n",
    "    print(f\"  - {filename_ed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a05e307-34be-483c-b2f1-5a14cf944e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_bstats(dataset_mean, dataset_median, dataset_std, top5, input_dict, variable_abreviation):\n",
    "\n",
    "    # Generate a timestamp for unique filenames\n",
    "    start_date = input_dict[\"start_datetime\"][:10]\n",
    "    end_date = input_dict[\"end_datetime\"][:10]\n",
    "\n",
    "    # define filenames \n",
    "    filename_median = f\"median_{variable_abreviation}_{start_date}-{end_date}.tif\"\n",
    "    filename_mean = f\"mean_{variable_abreviation}_{start_date}-{end_date}.tif\"\n",
    "    filename_top5 = f\"top5_{variable_abreviation}_{start_date}-{end_date}.tif\"\n",
    "    filename_std = f\"std_{variable_abreviation}_{start_date}-{end_date}.tif\"\n",
    "\n",
    "    # create filepaths\n",
    "    output_fp_median = os.path.join(DATA_DIRECTORY, filename_median)\n",
    "    output_fp_mean = os.path.join(DATA_DIRECTORY, filename_mean)\n",
    "    output_fp_top5 = os.path.join(DATA_DIRECTORY, filename_top5)\n",
    "    output_fp_std = os.path.join(DATA_DIRECTORY, filename_std)\n",
    "\n",
    "    # write to GeoTIFF\n",
    "    dataset_median.rio.to_raster(DATA_DIRECTORY / output_fp_median)\n",
    "    dataset_mean.rio.to_raster(DATA_DIRECTORY / output_fp_mean)\n",
    "    top5.rio.to_raster(DATA_DIRECTORY / output_fp_top5)\n",
    "    dataset_std.rio.to_raster(DATA_DIRECTORY / output_fp_std)\n",
    "\n",
    "    print(f\"Datsets saved in {DATA_DIRECTORY}:\")\n",
    "    print(f\"  - {filename_median}\")\n",
    "    print(f\"  - {filename_mean}\")\n",
    "    print(f\"  - {filename_top5}\")\n",
    "    print(f\"  - {filename_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8eef4-77ec-4a7a-8bf7-55ad00bb722a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd438c6c-4eed-4c31-ab1a-097fb4120dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-03-09T16:17:42Z - Selected dataset version: \"202311\"\n",
      "INFO - 2025-03-09T16:17:42Z - Selected dataset part: \"default\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset fetched via API and loaded into RAM\n"
     ]
    }
   ],
   "source": [
    "# fetching dataset details and loading it into the RAM by calling function\n",
    "dataset = get_cm_dataset(input_dict).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2fb1d-318e-4b55-b69e-4bb71af36716",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "654e3be3-869c-49ec-b3ce-352346e5b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset pre-processing finished\n"
     ]
    }
   ],
   "source": [
    "# pre-processing dataset by calling function\n",
    "dataset_preprocessed = pre_processing(dataset, variable_abreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b029d85d-06d6-43f5-9087-0cc64972cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics calculation finished\n"
     ]
    }
   ],
   "source": [
    "# calculating basic statistics by calling function\n",
    "dataset_mean, dataset_median, dataset_std = bstats(dataset_preprocessed, variable_abreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9430df-e32d-4dd2-acdd-4ae9dd5c4274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum sst: 10.69°C\n",
      "Maximum sst: 23.05°C\n",
      "Mean sst: 17.78°C\n",
      "Median sst: 17.59°C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print basic stats (min, max, mean and median\n",
    "print(f\"Minimum {variable_abreviation}: {round(dataset_preprocessed[variable_abreviation].min().item(),2)}{unit}\\n\"\n",
    "      f\"Maximum {variable_abreviation}: {round(dataset_preprocessed[variable_abreviation].max().item(), 2)}{unit}\\n\"\n",
    "      f\"Mean {variable_abreviation}: {round(dataset_preprocessed[variable_abreviation].mean().item(), 2)}{unit}\\n\"\n",
    "      f\"Median {variable_abreviation}: {round(dataset_preprocessed[variable_abreviation].median().item(), 2)}{unit}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bcb15-7d07-47ae-aedf-962c8abd6031",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2254f34-71aa-495a-834b-564811ce2054",
   "metadata": {},
   "source": [
    "### GETIS ORD G* Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "187c6c49-40c4-4d77-8f90-21c195cacf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of GETIS-ORD G* statistic finished\n"
     ]
    }
   ],
   "source": [
    "# calculating Getis Ord G* statistics by calling function\n",
    "getis_statistics = getis_ord_g(dataset_median, variable_abreviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226706b2-f194-4d95-9db4-4be4312dabde",
   "metadata": {},
   "source": [
    "### 5th Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "977e5fe6-f241-42c8-830a-1ca36fd5f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritzmuhlbauer/micromamba/envs/copernicusmarine/lib/python3.13/site-packages/numpy/lib/_nanfunctions_impl.py:1620: RuntimeWarning: All-NaN slice encountered\n",
      "  return fnb._ureduce(a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation of 5% highest values finished\n"
     ]
    }
   ],
   "source": [
    "# calling function to calculate the median over values > 95th percentile \n",
    "top5 = percentile_5th(dataset_preprocessed, variable_abreviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7492c-0cc4-440d-a49b-b87b423d4385",
   "metadata": {},
   "source": [
    "### GETIS ORD G* Statistic over 5 % highest values per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1adfa0fa-eabf-4c57-a112-2a94f01c7e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of GETIS-ORD G* statistic finished\n"
     ]
    }
   ],
   "source": [
    "# calculating GETIS ORD G* statistic over the median of the 5 % highest values over time per pixel\n",
    "getis_top5 = getis_ord_g(top5, variable_abreviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830995d-a963-4a72-9231-fd7462e41a46",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f395507-37a1-4773-9187-237c55d96472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved in /Users/moritzmuhlbauer/Copernicus/output/basic_plots:\n",
      " - mean_sst_2023-12-01-2024-02-28.png\n",
      " - median_sst_2023-12-01-2024-02-28.png\n",
      " - std_sst_2023-12-01-2024-02-28.png\n",
      " - top5_sst_2023-12-01-2024-02-28.png\n"
     ]
    }
   ],
   "source": [
    "# function call for plotting and saving basic stats plots \n",
    "visualization(dataset_mean, dataset_median, dataset_std, top5, input_dict, variable_abreviation, unit, DOI, temporal_resolution, spatial_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c03eb430-0ca3-497c-b42c-48be91393e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot of GETIS ORD G* Statistics saved to: /Users/moritzmuhlbauer/Copernicus/output/getis_plots/getis_top5_sst_2023-12-01-2024-02-28.png\n"
     ]
    }
   ],
   "source": [
    "# calling visualization function for getis statidtics \n",
    "getis_top5_viz(getis_top5, input_dict, variable_abreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82386240-62b6-46e2-8249-6f80ed44bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot of GETIS ORD G* Statistics saved to: /Users/moritzmuhlbauer/Copernicus/output/getis_plots/getis_entire_dataset_sst_2023-12-01-2024-02-28.png\n"
     ]
    }
   ],
   "source": [
    "# calling visualization function for getis statidtics \n",
    "getis_viz(getis_statistics, input_dict, variable_abreviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20c34e-c593-49f8-b171-b88d566adb7a",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e818d88-701f-4568-993c-c6cf19f07e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datsets saved in /Users/moritzmuhlbauer/Copernicus/output/data:\n",
      "  - getis_top5_sst_2023-12-01-2024-02-28.gpkg\n",
      "  - getis_entire_dataset_sst_2023-12-01-2024-02-28.gpkg\n"
     ]
    }
   ],
   "source": [
    "export_getis(getis_statistics, getis_top5, input_dict, variable_abreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df246bf9-c32b-4fe3-ac8c-c5a76e261392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944786d-daa3-4904-afaf-532b506d54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edc4b9e3-68f2-4c4d-a89b-d0c9b85928cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datsets saved in /Users/moritzmuhlbauer/Copernicus/output/data:\n",
      "  - median_sst_2023-12-01-2024-02-28.tif\n",
      "  - mean_sst_2023-12-01-2024-02-28.tif\n",
      "  - top5_sst_2023-12-01-2024-02-28.tif\n",
      "  - std_sst_2023-12-01-2024-02-28.tif\n"
     ]
    }
   ],
   "source": [
    "export_bstats(dataset_mean, dataset_median, dataset_std, top5, input_dict, variable_abreviation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CMT_Kernel)",
   "language": "python",
   "name": "copernicusmarine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
